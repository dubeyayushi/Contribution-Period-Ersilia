{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e01b3926-90c5-4e32-a7cb-32921de110f5",
   "metadata": {},
   "source": [
    "`Created by Ayushi Dubey`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aedb17-5be3-42cd-9611-355aa5e32fec",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb0bbb-a680-4df0-aa48-3907b0d92852",
   "metadata": {},
   "source": [
    "All the necessary libraries used in the notebook are imported in the below cell. The functions - `standardise_smiles` and `standardise_inchikey` described in the `src` directory are also imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae596bb-957a-4135-869e-5de836891a02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'smiles_processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msmiles_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m standardise_smiles\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minchikey_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m standardise_inchikey\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'smiles_processing'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ersilia import ErsiliaModel\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from smiles_processing import standardise_smiles\n",
    "from inchikey_processing import standardise_inchikey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b00c479-b824-496a-a5e4-6621e09d7c62",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ab3ba-c423-4c40-9882-eeb8def6c1c5",
   "metadata": {},
   "source": [
    "The dataset was downloaded from ChEMBL in tsv format. Dataset contains 8715 entries. Thus, it is preprocessed to check for null or irrelevant data and satisfy the required format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d84ccb-9ab2-4208-9aca-e4873bba1d5a",
   "metadata": {},
   "source": [
    "## Reading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519a120-4ba3-4d4d-9089-10dc154565c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bff5b6-17c1-422b-ada4-024500e23ed9",
   "metadata": {},
   "source": [
    "## Exploring the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be537f-7ea0-40af-90ac-ef1dfe8b5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca1ae0-b1f1-4ccd-994c-1c19ee9ece56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b3f01-03d4-4b13-b4d0-c8802401e0b4",
   "metadata": {},
   "source": [
    "We only require the `Smiles` and `Inchi Key` columns for further analysis. So we remove all the other columns except these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a89209-0695-4c46-8dce-317fd4ea032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Smiles', 'Inchi Key']\n",
    "df = df.loc[:, selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bda1a-cde9-44c5-88ea-9d764e828680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157858d-ceb6-4693-8fea-7f7838c6e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe34af1-b218-47b3-a4de-6da76435c64b",
   "metadata": {},
   "source": [
    "# Standardising Smiles and Inchi Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e39e52-299e-48f1-9ec7-4491c89a2968",
   "metadata": {},
   "source": [
    "We standardise both `Smiles` and `InChiKeys` of the molecules using the functions described in the `src` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0238d-70e9-4b47-b305-6d2dfe2f0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = df['Smiles'].tolist()\n",
    "standardised_smiles_list = standardise_smiles(smiles_list)\n",
    "df['standardised_smiles'] = standardised_smiles_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69054de0-d87c-4700-8747-a8bafdb3cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f9e7e2-1455-4cf2-a2a2-7580bbfb7862",
   "metadata": {},
   "source": [
    "Since few molecules could not be kekulized, we remove those rows from our dataset as they contain `NULL` entries in the `standardised_smiles` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3806c8df-2061-4dba-981e-a731027c3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcaa3fd-558c-4ced-b1f4-670cd012cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb0105e-c7d4-4363-ab3c-4d8c0b05e709",
   "metadata": {},
   "source": [
    "We standardise the `Inchi Key` column also using the function described in the `src` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a11e6-32cb-4cf5-b519-777e8a0c4165",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = df['standardised_smiles'].tolist()\n",
    "standardised_inchikeys_list = standardise_inchikey(smiles_list)\n",
    "df['standardised_inchikeys'] = standardised_inchikeys_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb268f6-fe15-46cf-be9d-7d05577ac059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cbf291-cdad-4938-8a20-e7b3c77dfc5f",
   "metadata": {},
   "source": [
    "Here, the preprocessing is completed. The dataset now contains 8697 entries. We now create a sample dataset of 1000 entries using the sample function. We also rename the column names to `Smiles` and `Inchi_key` for convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33552142-104f-434e-ab3c-cacdff25769a",
   "metadata": {},
   "source": [
    "# Creating the Sample of 1000 Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3584f9-9c3d-4101-b095-29bd4d37471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df.sample(n=1000, random_state=42)\n",
    "input_data = input_data[['standardised_inchikeys', 'standardised_smiles']]\n",
    "input_data.rename(columns={'standardised_inchikeys': 'Inchi_key', 'standardised_smiles': 'Smiles'}, inplace=True)\n",
    "input_data.reset_index(drop=True, inplace=True)\n",
    "input_data.to_csv('../data/input_data.csv', index=False)\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56345232-d795-4303-a57d-f3e8d30151d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e23a9d4-dc4b-4643-a070-e7045dd66ea0",
   "metadata": {},
   "source": [
    "# Running the Model on the Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de4982d-53b5-4d5e-b690-776003f793cf",
   "metadata": {},
   "source": [
    "The model is run on the terminal on the input data using the following commands:\n",
    "```\n",
    "ersilia -v fetch eos30gr\n",
    "ersilia serve eos30gr\n",
    "ersilia -v api run -i input_data.csv -o output_data.csv\n",
    "```\n",
    "\n",
    "The output after running the model is saved in `output_data.csv` file which is present the `data` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e9aba-0e21-47a2-b455-4a4d604cdec5",
   "metadata": {},
   "source": [
    "# Model Bias Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4157b-a2ab-42c8-944b-6f2450074380",
   "metadata": {},
   "source": [
    "## Exploring the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e60921-a504-44a0-8545-276ccbc0ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.read_csv('../data/output_data.csv')\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082fa5f-e8ee-42a8-b340-283bc41c4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455f06f-e2bc-48ab-9807-5fe1023a3265",
   "metadata": {},
   "source": [
    "The output data contains the `key` - which is the `InChiKey`, the `input` - which is the `Smiles` string and the `activity10` column which contains the `probability of hERG blockade`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a710e86-d655-4c0e-8d1d-f5453cae59cb",
   "metadata": {},
   "source": [
    "## Visualizing the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fdedec-4fe9-4c4b-b04f-148dc25c557e",
   "metadata": {},
   "source": [
    "### Molecules with highest predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac3580-6773-4e72-b834-ce889e104fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by predicted probabilities in descending order\n",
    "top_predictions = predictions_df.sort_values(by='activity10', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83888b-8be9-4ca6-a9b4-00e727512914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='activity10', y='input', data=top_predictions, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('SMILES')\n",
    "plt.title('Top 10 Molecules with Highest Predicted Probabilities')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3425c5c9-e4ec-4952-b3f3-8b747d04be55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f420b-18a4-4834-b5b8-cac9b7ad90d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d240e4-cd29-4b8b-bb7d-304af8546bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
